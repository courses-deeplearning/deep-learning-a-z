{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from google.colab import drive\r\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# importar el dataset\r\n",
    "dataset = pd.read_csv(\"/content/drive/MyDrive/deep learning/deep_learning_a-z/Part 1 - Artificial Neural Networks (ANN)/Churn_Modelling.csv\")\r\n",
    "X = dataset.iloc[:, 3:13].values\r\n",
    "y = dataset.iloc[:, 13].values\r\n",
    "\r\n",
    "\r\n",
    "# codificar datos categoricos\r\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "\r\n",
    "labelencoder_X_1 = LabelEncoder()\r\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\r\n",
    "\r\n",
    "labelencoder_X_2 = LabelEncoder()\r\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\r\n",
    "\r\n",
    "ctc = ColumnTransformer(\r\n",
    "    [('one_hot_encoder', OneHotEncoder(categories='auto'), [1])],   # The column numbers to be transformed (here is [0] but can be [0, 1, 3])\r\n",
    "    remainder='passthrough'                                         # Leave the rest of the columns untouched\r\n",
    ")\r\n",
    "X = ctc.fit_transform(X)\r\n",
    "X = X[:, 1:]\r\n",
    "\r\n",
    "# dividir el dataset en conjunto de entrenamiento i testing\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "sc_X = StandardScaler()\r\n",
    "X_train = sc_X.fit_transform(X_train)\r\n",
    "X_test = sc_X.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Cargar librerias\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense\r\n",
    "from keras.layers import Dropout\r\n",
    "\r\n",
    "from keras.models import load_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Cargar librerias\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense\r\n",
    "from keras.layers import Dropout\r\n",
    "\r\n",
    "from keras.models import load_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# entrenar  la RNA al dataset\r\n",
    "classifier.fit(X_train, y_train, batch_size=10, epochs=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save the model\r\n",
    "classifier.save('/content/drive/MyDrive/deep learning/deep_learning_a-z/Part 1 - Artificial Neural Networks (ANN)/my_model.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load de the model\r\n",
    "classifier = load_model('/content/drive/MyDrive/deep learning/deep_learning_a-z/Part 1 - Artificial Neural Networks (ANN)/my_model.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluar el modelo\r\n",
    "\r\n",
    "# Predicion de los datos del resultado con el conjunto de testing\r\n",
    "y_pred = classifier.predict(X_test)\r\n",
    "y_pred = (y_pred>0.5)\r\n",
    "\r\n",
    "# elaborar la matriz de confusion\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "\r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# porcentage de acierto \r\n",
    "(cm[0][0]+cm[1][1])/cm.sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# tarea despedir cliente en el banco\r\n",
    "new_prediction = classifier.predict(sc_X.transform(np.array([[0.0, 0.0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))\r\n",
    "\r\n",
    "\r\n",
    "# probabilidad de que el cliente abandone\r\n",
    "print(new_prediction)\r\n",
    "\r\n",
    "# True o False en cuanto se abandona\r\n",
    "print(new_prediction > 0.5)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
    "from sklearn.model_selection import cross_val_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def build_classifier():\r\n",
    "      # Inicializar la red\r\n",
    "  classifier = Sequential()\r\n",
    "\r\n",
    "  # primera capa oculta\r\n",
    "  classifier.add(Dense(units = 6, kernel_initializer=\"uniform\", activation = \"relu\", input_dim = 11))\r\n",
    "  # segunda capa oculta\r\n",
    "  classifier.add(Dense(units = 6 , kernel_initializer=\"uniform\", activation = \"relu\"))\r\n",
    "\r\n",
    "  # capa de salida\r\n",
    "  classifier.add(Dense(units = 1, kernel_initializer=\"uniform\", activation = \"sigmoid\"))\r\n",
    "\r\n",
    "\r\n",
    "  # compilar la red neuronal\r\n",
    "  classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\r\n",
    "\r\n",
    "  return classifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, nb_epoch = 100)\r\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv= 10, n_jobs = -1, verbose=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mean = accuracies.mean()\r\n",
    "var = accuracies.std()\r\n",
    "print(mean, var)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def build_classifier_grid_search(optimizer = \"adam\"):\r\n",
    "      # Inicializar la red\r\n",
    "  classifier = Sequential()\r\n",
    "\r\n",
    "  # primera capa oculta\r\n",
    "  classifier.add(Dense(units = 6, kernel_initializer=\"uniform\", activation = \"relu\", input_dim = 11))\r\n",
    "  # segunda capa oculta\r\n",
    "  classifier.add(Dense(units = 6 , kernel_initializer=\"uniform\", activation = \"relu\"))\r\n",
    "\r\n",
    "  # capa de salida\r\n",
    "  classifier.add(Dense(units = 1, kernel_initializer=\"uniform\", activation = \"sigmoid\"))\r\n",
    "\r\n",
    "\r\n",
    "  # compilar la red neuronal\r\n",
    "  classifier.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\r\n",
    "\r\n",
    "  return classifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# parametros para entrenar a la red\r\n",
    "\r\n",
    "parameters = {\r\n",
    "    'batch_size': [25, 32],\r\n",
    "    'nb_epoch': [100, 500],\r\n",
    "    'optimizer': ['adam', 'rmsprop']\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV\r\n",
    "\r\n",
    "classifier = KerasClassifier(build_fn = build_classifier )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid_search = GridSearchCV(estimator = classifier, \r\n",
    "                           param_grid = parameters, \r\n",
    "                           scoring = 'accuracy', \r\n",
    "                           cv = 10)\r\n",
    "\r\n",
    "grid_search = grid_search.fit(X_train, y_train)\r\n",
    "best_parameters = grid_search.best_params_\r\n",
    "best_accuracy = grid_search.best_score_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(best_parameters)\r\n",
    "print(best_accuracy)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}